# FractalGen MIDI ğŸ¹

åŸºæ–¼ FractalGen æ¶æ§‹çš„ MIDI éŸ³æ¨‚ç”Ÿæˆæ¨¡å‹ã€‚ä½¿ç”¨éšå±¤å¼ç”Ÿæˆæ–¹æ³•ï¼Œå¾ç²—åˆ°ç´°é€æ­¥ç”Ÿæˆ piano rollã€‚

## ğŸ“ æ–‡ä»¶çµæ§‹

```
FractalMIDI/
â”œâ”€â”€ config/                     # é…ç½®æª”æ¡ˆç›®éŒ„
â”‚   â”œâ”€â”€ train_default.yaml      # é è¨­è¨“ç·´é…ç½®
â”‚   â”œâ”€â”€ train_128x128.yaml      # å°å°ºå¯¸è¨“ç·´é…ç½®
â”‚   â”œâ”€â”€ train_ar.yaml           # AR ç”Ÿæˆå™¨é…ç½®
â”‚   â””â”€â”€ inference_default.yaml  # æ¨ç†é…ç½®
â”œâ”€â”€ models/                     # æ¨¡çµ„åŒ–æ¨¡å‹çµ„ä»¶
â”‚   â”œâ”€â”€ attention.py            # æ³¨æ„åŠ›æ©Ÿåˆ¶
â”‚   â”œâ”€â”€ blocks.py               # Transformer å€å¡Š
â”‚   â”œâ”€â”€ mar_generator.py        # MAR ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ ar_generator.py         # AR ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ velocity_loss.py        # åŠ›åº¦é æ¸¬å±¤
â”‚   â”œâ”€â”€ fractal_gen.py          # ä¸»è¦ FractalGen æ¨¡å‹
â”‚   â”œâ”€â”€ generation.py           # ç”Ÿæˆå‡½æ•¸
â”‚   â””â”€â”€ utils.py                # å·¥å…·å‡½æ•¸
â”œâ”€â”€ docs/                       # æ–‡æª”
â”‚   â”œâ”€â”€ archive/                # æ­·å²æ–‡æª”
â”‚   â”œâ”€â”€ MODEL_STRUCTURE.md      # æ¨¡å‹çµæ§‹èªªæ˜
â”‚   â”œâ”€â”€ TRAINING_GUIDE.md       # è¨“ç·´æŒ‡å—
â”‚   â””â”€â”€ ...                     # å…¶ä»–æ–‡æª”
â”œâ”€â”€ tests/                      # æ¸¬è©¦æª”æ¡ˆ
â”œâ”€â”€ dataset/                    # æ•¸æ“šé›†åˆ—è¡¨
â”œâ”€â”€ trainer.py                  # PyTorch Lightning è¨“ç·´å™¨
â”œâ”€â”€ dataset.py                  # MIDI æ•¸æ“šåŠ è¼‰èˆ‡é è™•ç†
â”œâ”€â”€ visualizer.py               # Piano roll å¯è¦–åŒ–å·¥å…·
â”œâ”€â”€ model.py                    # æ¨¡å‹æ¥å£ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
â”œâ”€â”€ main.py                     # è¨“ç·´ä¸»ç¨‹åº
â”œâ”€â”€ inference.py                # æ¨ç†ç¨‹åº
â”œâ”€â”€ run_training.sh             # è¨“ç·´è…³æœ¬
â”œâ”€â”€ run_inference.sh            # æ¨ç†è…³æœ¬
â””â”€â”€ requirements.txt            # ä¾è³´
```

**æ¨¡çµ„åŒ–çµæ§‹**ï¼šæ¨¡å‹ä»£ç¢¼å·²é‡æ§‹ç‚ºæ¨¡çµ„åŒ–çµæ§‹ï¼Œæå‡å¯è®€æ€§å’Œå¯ç¶­è­·æ€§ã€‚è©³è¦‹ [docs/MODEL_STRUCTURE.md](docs/MODEL_STRUCTURE.md)ã€‚

**é…ç½®ç³»çµ±**ï¼šä½¿ç”¨ YAML é…ç½®æª”æ¡ˆç®¡ç†æ‰€æœ‰è¶…åƒæ•¸ï¼Œæ–¹ä¾¿å¯¦é©—ç®¡ç†å’Œç‰ˆæœ¬æ§åˆ¶ã€‚

## âš¡ å¿«é€Ÿé–‹å§‹

### 1. ç’°å¢ƒè¨­ç½®

```bash
# å‰µå»ºç’°å¢ƒ
conda create -n frac python=3.10
conda activate frac

# å®‰è£ä¾è³´
pip install -r requirements.txt
```

### 2. æº–å‚™æ•¸æ“š

#### æ–¹æ³• 1: ä½¿ç”¨ preprocess.pyï¼ˆæ¨è–¦ï¼‰

è‡ªå‹•ç”Ÿæˆè¨“ç·´/é©—è­‰/æ¸¬è©¦é›†åˆ†å‰²ï¼ˆ99.8% / 0.1% / 0.1%ï¼‰ï¼š

```bash
# POP909 è³‡æ–™é›†
python preprocess.py --dataset pop909

# Aria MIDI è³‡æ–™é›† (aria-midi-v1-unique-ext)
python preprocess.py --dataset ariamidi

# è‡ªè¨‚è¼¸å‡ºç›®éŒ„ï¼ˆå¯é¸ï¼‰
python preprocess.py --dataset ariamidi --output-dir /path/to/output
```

é€™æœƒè‡ªå‹•ç”¢ç”Ÿä»¥ä¸‹æª”æ¡ˆï¼š
- `dataset/{dataset_name}/train.txt` - è¨“ç·´é›†æª”æ¡ˆåˆ—è¡¨
- `dataset/{dataset_name}/valid.txt` - é©—è­‰é›†æª”æ¡ˆåˆ—è¡¨
- `dataset/{dataset_name}/test.txt` - æ¸¬è©¦é›†æª”æ¡ˆåˆ—è¡¨

**æ”¯æ´çš„è³‡æ–™é›†ï¼š**
- `pop909`: POP909 è³‡æ–™é›† (`~/dataset/POP909-Dataset/POP909`)
- `ariamidi`: Aria MIDI v1 è³‡æ–™é›† (`~/dataset/aria-midi-v1-unique-ext/data`)

#### æ–¹æ³• 2: æ‰‹å‹•å‰µå»ºåˆ—è¡¨

```bash
# å‰µå»ºæ•¸æ“šé›†åˆ—è¡¨
find /path/to/midi/files -name "*.mid" > dataset/train.txt
find /path/to/validation/files -name "*.mid" > dataset/valid.txt
```

### 3. é–‹å§‹è¨“ç·´

```bash
# ä½¿ç”¨é…ç½®æª”æ¡ˆï¼ˆæ¨è–¦ï¼‰
bash run_training.sh config/train_default.yaml

# æˆ–ä½¿ç”¨ä¸åŒçš„é…ç½®
bash run_training.sh config/train_ar.yaml         # å…¨ AR ç”Ÿæˆå™¨
bash run_training.sh config/train_128x128.yaml    # å°å°ºå¯¸å¿«é€Ÿæ¸¬è©¦

# ç›´æ¥ä½¿ç”¨ Pythonï¼ˆé…ç½®æª”æ¡ˆï¼‰
python main.py --config config/train_default.yaml

# è¦†å¯«é…ç½®ä¸­çš„ç‰¹å®šåƒæ•¸
python main.py --config config/train_default.yaml --max_steps 100000 --lr 5e-5

# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
python main.py \
    --train_batch_size 8 \
    --val_batch_size 8 \
    --max_steps 200000 \
    --val_check_interval_steps 2000 \
    --checkpoint_every_n_steps 2000 \
    --devices 0,1 \
    --generator_types "ar,ar,ar,ar" \
    --scan_order "row_major"
```

**å¯ç”¨çš„é…ç½®æª”æ¡ˆï¼š**
- `config/train_default.yaml`: é è¨­é…ç½®ï¼ˆ128x512, MAR generatorsï¼‰
- `config/train_128x256.yaml`: ä¸­å°ºå¯¸è¨“ç·´ï¼ˆ128x256, å¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡ï¼‰
- `config/train_128x128.yaml`: å°å°ºå¯¸è¨“ç·´ï¼ˆ128x128, æ›´å¿«ï¼‰

**é…ç½®é¸é …ï¼š**
- `generator_types`: æ¯å±¤çš„ç”Ÿæˆå™¨é¡å‹ï¼Œå¯é¸ `mar` æˆ– `ar`
- `scan_order`: AR ç”Ÿæˆå™¨çš„æƒæé †åº
  - `row_major`ï¼ˆé è¨­ï¼‰ï¼šå…ˆå·¦åˆ°å³ï¼Œå†ä¸Šåˆ°ä¸‹ï¼ˆå¼·èª¿æ™‚é–“é€£çºŒæ€§ï¼‰
  - `column_major`ï¼šå…ˆä¸Šåˆ°ä¸‹ï¼Œå†å·¦åˆ°å³ï¼ˆå¼·èª¿å’Œè²çµæ§‹ï¼‰

### 4. ç›£æ§è¨“ç·´

```bash
tensorboard --logdir outputs/fractalgen
```

**TensorBoard ä¸­çš„å¯è¦–åŒ–ï¼š**
- `train/loss`, `val_loss`: è¨“ç·´å’Œé©—è­‰æå¤±
- `val/ground_truth/`: é©—è­‰é›†çš„çœŸå¯¦ piano rolls
- `val/generated/`: æ¨¡å‹ç”Ÿæˆçš„ piano rolls
- `val/generation_preview/`: GIF å‹•ç•«çš„æœ€å¾Œä¸€å¹€é è¦½

**Generation GIF å‹•ç•«ï¼š**
åœ¨æ¯å€‹ `log_images_every_n_steps` æ™‚ï¼Œæ¨¡å‹æœƒç”Ÿæˆå¸¶æœ‰ä¸­é–“æ­¥é©Ÿçš„å‹•ç•« GIFï¼Œå±•ç¤ºç”Ÿæˆéç¨‹ï¼š
```bash
# GIF å„²å­˜ä½ç½®
outputs/fractalgen_ar_ar_ar_ar/lightning_logs/version_X/generation_gifs/
â”œâ”€â”€ step_0010000_sample_0.gif
â”œâ”€â”€ step_0010000_sample_1.gif
â”œâ”€â”€ step_0010000_sample_2.gif
â””â”€â”€ step_0010000_sample_3.gif
```
æ¯å€‹ GIF å±•ç¤ºæ¨¡å‹å¦‚ä½•å¾ç²—ç•¥åˆ°ç²¾ç´°é€æ­¥ç”Ÿæˆ piano rollï¼Œå¹«åŠ©ç†è§£éšå±¤å¼ç”Ÿæˆéç¨‹ã€‚

### 5. ç”Ÿæˆ MIDI

```bash
# ä½¿ç”¨è…³æœ¬ï¼ˆæ¨è–¦ï¼‰
bash run_inference.sh outputs/fractalgen/checkpoints/step_00100000.ckpt

# ä½¿ç”¨é…ç½®æª”æ¡ˆ
python inference.py \
    --config config/inference_default.yaml \
    --checkpoint outputs/fractalgen/checkpoints/step_00100000.ckpt

# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰

# ç„¡æ¢ä»¶ç”Ÿæˆ
python inference.py \
    --checkpoint outputs/fractalgen/checkpoints/step_00100000.ckpt \
    --mode unconditional \
    --num_samples 10 \
    --generation_length 256 \
    --save_images

# æœ‰æ¢ä»¶ç”Ÿæˆï¼ˆåŸºæ–¼å‰ç¶´ï¼‰
python inference.py \
    --checkpoint outputs/fractalgen/checkpoints/step_00100000.ckpt \
    --mode conditional \
    --condition_midi input.mid \
    --condition_length 64 \
    --generation_length 256 \
    --save_images

# Inpaintingï¼ˆå±€éƒ¨é‡æ–°ç”Ÿæˆï¼‰
python inference.py \
    --checkpoint outputs/fractalgen/checkpoints/step_00100000.ckpt \
    --mode inpainting \
    --input_midi input.mid \
    --mask_start 64 \
    --mask_end 192 \
    --save_images
```

## ğŸ—ï¸ æ¨¡å‹æ¶æ§‹

### FractalGen éšå±¤çµæ§‹

```
Level 0 (128 patches): PianoRollMAR
    â†“ (æ¯å€‹ patch ç”Ÿæˆä¸‹ä¸€å±¤çš„æ¢ä»¶)
Level 1 (4 patches): PianoRollMAR
    â†“ (æ¯å€‹ patch ç”Ÿæˆåƒç´ å€¼)
Level 2 (1 patch): PianoRollVelocityLoss
```

### é—œéµç‰¹æ€§

- **éšå±¤å¼ç”Ÿæˆ**: ç²—åˆ°ç´°ï¼Œé€æ­¥ç²¾ç·»åŒ–
- **MAR (Masked Autoregressive)**: ä½¿ç”¨é®ç½©ç­–ç•¥é€²è¡Œè¨“ç·´
- **Iterative Refinement**: ç”Ÿæˆæ™‚é€æ­¥å¡«å……è¢«é®ç½©çš„å€åŸŸ
- **Classifier-Free Guidance**: æå‡ç”Ÿæˆè³ªé‡
- **å¯è®Šé•·åº¦æ”¯æŒ**: è‡ªå‹•è™•ç†ä¸åŒé•·åº¦çš„è¼¸å…¥

### æ¨¡å‹è¦æ¨¡

ç›®å‰ç‰ˆæœ¬åƒ…æä¾›å–®ä¸€é…ç½®ï¼ˆç´„ 30M åƒæ•¸ï¼‰ï¼Œå°æ‡‰ `768/384/192` çš„å±¤ç´šåµŒå…¥ç¶­åº¦èˆ‡ `16/4/2/1` çš„ Transformer block æ•¸é‡ï¼Œå¯åœ¨ 8GB GPU ä¸Šä»¥ `batch_size=8` é †åˆ©è¨“ç·´ã€‚

## ğŸ›ï¸ é‡è¦åƒæ•¸

### è¨“ç·´åƒæ•¸

```python
--train_batch_size 8              # è¨“ç·´æ‰¹æ¬¡å¤§å°ï¼ˆå–® GPUï¼‰
--val_batch_size 8                # é©—è­‰æ‰¹æ¬¡å¤§å°
--max_steps 200000               # ç¸½è¨“ç·´æ­¥æ•¸
--val_check_interval_steps 2000  # æ¯éš”å¤šå°‘æ­¥é©—è­‰ä¸€æ¬¡
--checkpoint_every_n_steps 2000  # æ¯éš”å¤šå°‘æ­¥å„²å­˜æ¨¡å‹
--lr 1e-4                        # å­¸ç¿’ç‡
--weight_decay 0.05              # æ¬Šé‡è¡°æ¸›
--warmup_steps 2000              # Warmup æ­¥æ•¸
--accumulate_grad_batches 1      # æ¢¯åº¦ç´¯ç©æ­¥æ•¸
--grad_clip 3.0                  # æ¢¯åº¦è£å‰ª
--devices 0,1                    # ä½¿ç”¨çš„ GPU
--precision 32                   # ç²¾åº¦ (32/16/bf16)
--log_images_every_n_steps 5000  # ç”Ÿæˆæ¨£æœ¬é »ç‡ï¼ˆ0 é—œé–‰ï¼‰
--cache_dir ./cache              # ï¼ˆé¸ï¼‰piano roll å¿«å–ç›®éŒ„
--no_cache_in_memory             # ï¼ˆé¸ï¼‰åœç”¨è¨˜æ†¶é«”å¿«å–
```

### ç”Ÿæˆåƒæ•¸

```python
--num_iter_list 12 8 1         # æ¯å±¤çš„è¿­ä»£æ¬¡æ•¸ [Level0, Level1, Level2]
--cfg 1.0                      # Classifier-free guidance å¼·åº¦
--temperature 1.0              # æ¡æ¨£æº«åº¦
--sparsity_bias 2.0            # ç¨€ç–æ€§åç½®ï¼ˆè¶Šé«˜è¶Šç¨€ç–ï¼‰
```

## ğŸ“Š æ•¸æ“šæ ¼å¼

### Piano Roll æ ¼å¼

- **å½¢ç‹€**: `(1, 128, T)`
  - é€šé“: 1 (velocity)
  - é«˜åº¦: 128 (MIDI éŸ³é«˜ 0-127)
  - å¯¬åº¦: T (æ™‚é–“æ­¥ï¼Œå–®ä½ç‚º 16th note)
- **å€¼åŸŸ**: `[0, 1]`ï¼ˆæ­¸ä¸€åŒ–çš„ velocityï¼‰

### Patch åŠƒåˆ†

ä½¿ç”¨ `patch_size=4` å°‡ piano roll åŠƒåˆ†ç‚º patchesï¼ˆpitch ç¶­åº¦å›ºå®šç‚º 128ï¼‰:
- 128x512 â†’ 4096 patches (32x32) [é è¨­]
- 128x256 â†’ 2048 patches (32x16)
- 128x128 â†’ 1024 patches (32x8)

## ğŸ¨ å¯è¦–åŒ–

Piano roll å¯è¦–åŒ–éµå¾ª Logic Pro é¢¨æ ¼ï¼š
- **é»‘è‰²**: ç„¡éŸ³ç¬¦ (velocity = 0)
- **ç¶ è‰²**: ä¸­ç­‰åŠ›åº¦ (velocity â‰ˆ 64)
- **ç´…è‰²**: å¼·åŠ›åº¦ (velocity â‰ˆ 127)

## ğŸ”§ é…ç½®ç³»çµ±

### YAML é…ç½®æª”æ¡ˆ

ä½¿ç”¨ YAML æª”æ¡ˆç®¡ç†æ‰€æœ‰è¶…åƒæ•¸ï¼Œæ–¹ä¾¿å¯¦é©—ç®¡ç†ï¼š

```yaml
# config/train_default.yaml ç¯„ä¾‹

# æ¨¡å‹é…ç½®
model:
  generator_types: [mar, mar, mar, mar]
  scan_order: row_major
  mask_ratio_loc: 1.0
  mask_ratio_scale: 0.5
  grad_checkpointing: false

# è¨“ç·´é…ç½®
training:
  max_steps: 200000
  learning_rate: 1.0e-4
  weight_decay: 0.05
  warmup_steps: 2000
  grad_clip: 3.0
  accumulate_grad_batches: 1
  train_batch_size: 8
  val_batch_size: 8

# æ•¸æ“šé…ç½®
data:
  train_data: dataset/ariamidi/train.txt  # ä½¿ç”¨ preprocess.py ç”Ÿæˆçš„åˆ—è¡¨
  val_data: dataset/ariamidi/valid.txt
  crop_length: 512                        # æ™‚é–“ç¶­åº¦é•·åº¦ï¼ˆ128x512 piano rollï¼‰
  augment_factor: 1
  pitch_shift_min: -3
  pitch_shift_max: 3

# ç¡¬é«”é…ç½®
hardware:
  devices: [0, 1]
  num_workers: 4
  precision: "32"

# æ—¥èªŒé…ç½®
logging:
  output_dir: outputs/fractalgen
  val_check_interval_steps: 2000
  checkpoint_every_n_steps: 2000
  log_images_every_n_steps: 5000
```

### Dataclass é…ç½®ï¼ˆå…§éƒ¨ï¼‰

ç¨‹å¼ç¢¼å…§éƒ¨ä½¿ç”¨ dataclass ç®¡ç†é…ç½®ï¼š

```python
# trainer.py
@dataclass
class FractalTrainerConfig:
    max_steps: int = 200000
    grad_clip: float = 3.0
    accumulate_grad_batches: int = 1
    # ...

# dataset.py
@dataclass
class DataLoaderConfig:
    num_workers: int = 4
    pin_memory: bool = True
    # ...
```

YAML é…ç½®æœƒè‡ªå‹•è½‰æ›ç‚ºå°æ‡‰çš„ dataclass å¯¦ä¾‹ã€‚

## ğŸ“ˆ è¨“ç·´æµç¨‹

### éšå±¤å¼ Loss

```python
# è‡ªå‹•è¨ˆç®—æ‰€æœ‰å±¤çš„ loss
loss = model(piano_rolls)

# ç­‰åƒ¹æ–¼ï¼š
loss = (
    loss_level0 +  # PianoRollMAR (ç²—å±¤)
    loss_level1 +  # PianoRollMAR (ä¸­å±¤)
    loss_level2    # PianoRollVelocityLoss (ç´°å±¤)
)
```

### æ¡æ¨£æµç¨‹

```python
# Iterative refinement
for level in [0, 1, 2]:
    for iteration in range(num_iter_list[level]):
        1. å‰µå»ºé®ç½©ï¼ˆcosine scheduleï¼‰
        2. é æ¸¬è¢«é®ç½©çš„ patches
        3. å¡«å……é æ¸¬å€¼
        4. é€²å…¥ä¸‹ä¸€å±¤æˆ–ä¸‹ä¸€æ¬¡è¿­ä»£
```

## ğŸ”¬ å¯¦é©—è¨­ç½®

### æ¨è–¦è¨­ç½®

```bash
# ä½¿ç”¨é…ç½®æª”æ¡ˆï¼ˆæ¨è–¦ï¼‰
python main.py --config config/train_default.yaml

# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸
python main.py \
    --train_batch_size 8 \
    --val_batch_size 8 \
    --augment_factor 2 \
    --pitch_shift_min -3 \
    --pitch_shift_max 3 \
    --generator_types mar,mar,mar,mar \
    --max_steps 240000 \
    --val_check_interval_steps 2000 \
    --checkpoint_every_n_steps 2000 \
    --lr 1e-4 \
    --warmup_steps 4000 \
    --devices 0,1 \
    --precision 32 \
    --log_images_every_n_steps 0
```

### é æœŸ Loss

- **åˆå§‹**: ~5.5-5.6
- **æ”¶æ–‚**: ~1.0-2.0 (å–æ±ºæ–¼æ•¸æ“šé›†)
- **è‰¯å¥½**: <0.5

## âš ï¸ å·²çŸ¥é™åˆ¶

### 1. ç”Ÿæˆç¶­åº¦å•é¡Œ

- **ç‹€æ…‹**: æ¢ä»¶ç”Ÿæˆå’Œ inpainting çš„ç¶­åº¦åŒ¹é…éœ€è¦é€²ä¸€æ­¥èª¿è©¦
- **å»ºè­°**: å…ˆå°ˆæ³¨æ–¼è¨“ç·´ï¼Œå¾…æ¨¡å‹æ”¶æ–‚å¾Œå†å„ªåŒ–ç”Ÿæˆ
- **æ›¿ä»£æ–¹æ¡ˆ**: ä½¿ç”¨ç„¡æ¢ä»¶ç”Ÿæˆï¼ˆå·²å¯ç”¨ï¼‰

### 2. é•·åºåˆ—

- **é™åˆ¶**: é è¨­ `max_seq_len=2100`ï¼Œå¯è™•ç† 128x256 å·¦å³çš„è¼¸å…¥ï¼›å°æ–¼ 128x512 éœ€è¦æ›´å¤§çš„ `max_seq_len`
- **è§£æ±º**: å¦‚éœ€æ›´é•·åºåˆ—ï¼ˆå¦‚ 128x512ï¼‰ï¼Œèª¿æ•´ `TrainerConfig.max_seq_len` è‡³å°‘ç‚º 4096

### 3. è¨˜æ†¶é«”ä½¿ç”¨

- ç´„ 8GB (batch_size=8)

## ğŸ“š åƒè€ƒæ–‡ä»¶

### æ–‡æª”ç›®éŒ„

- **è¨“ç·´æŒ‡å—**: [docs/TRAINING_GUIDE.md](docs/TRAINING_GUIDE.md)
- **æ¨¡å‹çµæ§‹**: [docs/MODEL_STRUCTURE.md](docs/MODEL_STRUCTURE.md)
- **GIF ç”Ÿæˆ**: [docs/GIF_GENERATION_GUIDE.md](docs/GIF_GENERATION_GUIDE.md)
- **Checkpoint æŒ‡å—**: [docs/CHECKPOINT_MISMATCH_GUIDE.md](docs/CHECKPOINT_MISMATCH_GUIDE.md)

### æ­·å²æ–‡æª”ï¼ˆå­˜æª”ï¼‰

- [docs/archive/](docs/archive/)

### åŸå§‹åƒè€ƒ

- **åŸè«–æ–‡**: https://arxiv.org/abs/2401.05036
- **åŸä»£ç¢¼**: https://github.com/Yikai-Liao/fractalgen

## ğŸ› æ•…éšœæ’é™¤

### è¨“ç·´ Loss ä¸ä¸‹é™

```bash
# æª¢æŸ¥æ•¸æ“š
python -c "
from dataset import create_dataloader, DataLoaderConfig
cfg = DataLoaderConfig.training_default('dataset/train.txt')
cfg.sampler.batch_size = 4
cfg.num_workers = 0
loader = create_dataloader(config=cfg)
batch = next(iter(loader))
print(f'Batch shape: {batch[0].shape}')
print(f'Value range: [{batch[0].min():.3f}, {batch[0].max():.3f}]')
if len(batch) > 2:
    print(f'Pitch shifts: {batch[2].tolist()}')
"

# é™ä½å­¸ç¿’ç‡
python main_fractalgen.py --lr 5e-5

# å¢åŠ  warmup
python main_fractalgen.py --warmup_steps 4000
```

### è¨˜æ†¶é«”ä¸è¶³

```bash
# æ¸›å°æ‰¹æ¬¡å¤§å°
python main_fractalgen.py --train_batch_size 2

# å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»ï¼ˆç•¥é™é€Ÿåº¦æ›å–è¨˜æ†¶é«”ï¼‰
python main_fractalgen.py --grad_checkpoint

# ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆè¬¹æ…ï¼‰
python main_fractalgen.py --precision bf16
```

### ç”Ÿæˆçµæœå¤ªç¨€ç–

```python
# é™ä½ç¨€ç–æ€§åç½®
python inference_fractalgen.py --sparsity_bias 1.0

# èª¿æ•´æº«åº¦
python inference_fractalgen.py --temperature 1.2
```

### ç”Ÿæˆçµæœå¤ªå¯†é›†

```python
# å¢åŠ ç¨€ç–æ€§åç½®
python inference_fractalgen.py --sparsity_bias 3.0

# é™ä½æº«åº¦
python inference_fractalgen.py --temperature 0.8
```

## ğŸ¯ æœ€ä½³å¯¦è¸

### 1. æ•¸æ“šæº–å‚™

- ç¢ºä¿ MIDI æ–‡ä»¶è³ªé‡è‰¯å¥½
- å»ºè­°è‡³å°‘ 1000 é¦–æ›²ç›®
- é©—è­‰é›†ç´„ä½” 10-20%

### 2. è¨“ç·´ç­–ç•¥

- ç›®å‰åƒ…æä¾›å–®ä¸€æ¨¡å‹é…ç½®ï¼Œå»ºè­°å…ˆä»¥çŸ­è¨“ç·´é©—è­‰æµç¨‹
- ç›£æ§ TensorBoard çš„é‡å»ºåœ–åƒè³ªé‡èˆ‡éšå±¤å¼æŒ‡æ¨™

### 3. ç”Ÿæˆç­–ç•¥

- å…ˆç”¨ç„¡æ¢ä»¶ç”Ÿæˆæ¸¬è©¦æ¨¡å‹
- èª¿æ•´ `num_iter_list` å¹³è¡¡é€Ÿåº¦/è³ªé‡
- å¯¦é©—ä¸åŒçš„ `sparsity_bias` å€¼

### 4. èª¿åƒå»ºè­°

```python
# å¿«é€Ÿå¯¦é©—
num_iter_list = [4, 2, 1]  # æœ€å¿«

# å¹³è¡¡è³ªé‡/é€Ÿåº¦
num_iter_list = [8, 4, 1]  # æ¨è–¦

# æœ€ä½³è³ªé‡
num_iter_list = [16, 8, 1]  # æœ€æ…¢
```

## ğŸ“ ç†è§£ FractalGen

### æ ¸å¿ƒæ¦‚å¿µ

1. **éšå±¤ç”Ÿæˆ**: å¾ç²—ç³™åˆ°ç²¾ç´°ï¼Œé€å±¤ç”Ÿæˆ
2. **MAR masking**: è¨“ç·´æ™‚éš¨æ©Ÿé®ç½©éƒ¨åˆ† patches
3. **Iterative refinement**: ç”Ÿæˆæ™‚é€æ­¥å¡«å……é®ç½©å€åŸŸ
4. **Classifier-free guidance**: æ··åˆæ¢ä»¶/ç„¡æ¢ä»¶é æ¸¬

### èˆ‡å‚³çµ±æ–¹æ³•çš„å€åˆ¥

| ç‰¹æ€§ | å‚³çµ± Transformer | FractalGen |
|------|-----------------|------------|
| ç”Ÿæˆæ–¹å¼ | åºåˆ—åŒ–ï¼ˆé€å€‹ tokenï¼‰ | éšå±¤åŒ–ï¼ˆç²—åˆ°ç´°ï¼‰ |
| è¨“ç·´ç›®æ¨™ | ä¸‹ä¸€å€‹ token | è¢«é®ç½©çš„ patches |
| æ¡æ¨£ | Autoregressive | Iterative refinement |
| é€Ÿåº¦ | O(T) | O(log T) ç†è«–ä¸Š |
| ä¸¦è¡Œæ€§ | ä½ | é«˜ |

## ğŸ’¡ Tips

### åŠ é€Ÿè¨“ç·´

- ä½¿ç”¨å¤š GPU: `--devices 0,1,2,3`
- å¢åŠ  workers: `--num_workers 8`
- ä½¿ç”¨ SSD å­˜å„²æ•¸æ“š
- è€ƒæ…®æ··åˆç²¾åº¦: `--precision bf16`ï¼ˆå¯¦é©—æ€§ï¼‰

### æå‡è³ªé‡

- å»¶é•·è¨“ç·´: `--max_steps 400000`
- æ•¸æ“šå¢å¼·ï¼ˆå·²å…§å»ºéš¨æ©Ÿè£å‰ªï¼‰
- èª¿æ•´æ¡æ¨£åƒæ•¸

### èª¿è©¦æŠ€å·§

```bash
# å¿«é€Ÿæ¸¬è©¦ï¼ˆ1å€‹ batchï¼‰
python main.py --config config/train_default.yaml --fast_dev_run

# æª¢æŸ¥æ¨¡å‹
python -c "
from model import fractalmar_piano
model = fractalmar_piano()
print(f'Parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M')
"

# æª¢æŸ¥æ•¸æ“š
python -c "
from dataset import create_dataloader, DataLoaderConfig
cfg = DataLoaderConfig.training_default('dataset/train.txt')
cfg.sampler.batch_size = 2
loader = create_dataloader(config=cfg)
for i, batch in enumerate(loader):
    print(f'Batch {i}: {batch[0].shape}')
    if i >= 2: break
"
```

## ğŸš€ ä¸‹ä¸€æ­¥

### çŸ­æœŸï¼ˆ1-2é€±ï¼‰

1. âœ… å®Œæˆæ¨¡å‹è¨“ç·´æµç¨‹é©—è­‰
2. âœ… ç›£æ§ loss å’Œé‡å»ºåœ–åƒ
3. âš ï¸  èª¿è©¦ç”Ÿæˆå‡½æ•¸ç¶­åº¦å•é¡Œ

### ä¸­æœŸï¼ˆ1-2æœˆï¼‰

4. å®Œå–„ conditional generation
5. å®Œå–„ inpainting
6. å„ªåŒ–æ¡æ¨£é€Ÿåº¦

### é•·æœŸï¼ˆ3-6æœˆï¼‰

7. æ¢ç´¢æ›´å¤§çš„æ¨¡å‹å’Œæ•¸æ“šé›†
8. å¯¦é©—ä¸åŒçš„ architecture è®Šé«”
9. ç™¼å¸ƒé è¨“ç·´æ¨¡å‹

---

**ğŸ‰ é–‹å§‹ä½ çš„ FractalGen MIDI ç”Ÿæˆä¹‹æ—…å§ï¼**

å¦‚æœ‰å•é¡Œï¼Œè«‹æŸ¥é–±ï¼š
- [docs/TRAINING_GUIDE.md](docs/TRAINING_GUIDE.md) - è¨“ç·´æŒ‡å—
- [docs/MODEL_STRUCTURE.md](docs/MODEL_STRUCTURE.md) - æ¨¡å‹çµæ§‹
- [docs/](docs/) - å®Œæ•´æ–‡æª”ç›®éŒ„

