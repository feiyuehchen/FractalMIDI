# FractalMIDI è¨“ç·´æŒ‡å—

## å¿«é€Ÿé–‹å§‹

### 1. æ¸¬è©¦è¨“ç·´è¨­ç½®

é¦–å…ˆé‹è¡Œå¿«é€Ÿæ¸¬è©¦ç¢ºèªç’°å¢ƒæ­£å¸¸ï¼š

```bash
bash train_test.sh
```

é€™æœƒé‹è¡Œå¹¾å€‹è¨“ç·´æ­¥é©Ÿä¾†é©—è­‰ï¼š
- è³‡æ–™è¼‰å…¥æ­£å¸¸
- æ¨¡å‹å¯ä»¥æ­£å¸¸å‰å‘å‚³æ’­
- GPU è¨˜æ†¶é«”è¶³å¤ 
- æ‰€æœ‰ä¾è³´æ­£ç¢ºå®‰è£

### 2. é¸æ“‡æ¨¡å‹å¤§å°

æ ¹æ“šæ‚¨çš„éœ€æ±‚é¸æ“‡æ¨¡å‹å¤§å°ï¼š

#### 128Ã—128 æ¨¡å‹ï¼ˆæ¨è–¦å…¥é–€ï¼‰

**ç‰¹é»ï¼š**
- è¨“ç·´å°ºå¯¸ï¼š128 pitches Ã— 128 time steps
- æ™‚é•·ï¼š8 measures (4/4 time)
- è¨˜æ†¶é«”éœ€æ±‚ï¼š~4-6GB per GPU
- è¨“ç·´é€Ÿåº¦ï¼šè¼ƒå¿«
- é©ç”¨å ´æ™¯ï¼šçŸ­æ—‹å¾‹ã€å‹•æ©Ÿã€å¿«é€Ÿè¿­ä»£

**è¨“ç·´å‘½ä»¤ï¼š**
```bash
bash train_128x128.sh
```

**æˆ–æ‰‹å‹•æŒ‡å®šï¼š**
```bash
python main.py \
    --crop_length 128 \
    --train_batch_size 16 \
    --output_dir outputs/my_128x128_model
```

#### 256Ã—256 æ¨¡å‹ï¼ˆå¯¦éš› 128Ã—512ï¼‰

**ç‰¹é»ï¼š**
- è¨“ç·´å°ºå¯¸ï¼š128 pitches Ã— 512 time steps
- é¡¯ç¤ºæ ¼å¼ï¼š256Ã—256ï¼ˆè¦–è¦ºåŒ–ç”¨é€”ï¼Œå‚ç›´å †ç–Šå…©æ®µï¼‰
- æ™‚é•·ï¼š32 measures (4/4 time)
- è¨˜æ†¶é«”éœ€æ±‚ï¼š~12-16GB per GPU
- è¨“ç·´é€Ÿåº¦ï¼šè¼ƒæ…¢
- é©ç”¨å ´æ™¯ï¼šå®Œæ•´æ¨‚å¥ã€é•·æœŸéŸ³æ¨‚çµæ§‹

**è¨“ç·´å‘½ä»¤ï¼š**
```bash
bash train_256x256.sh
```

**æˆ–æ‰‹å‹•æŒ‡å®šï¼š**
```bash
python main.py \
    --crop_length 512 \
    --train_batch_size 4 \
    --output_dir outputs/my_256x256_model
```

## å®Œæ•´å‘½ä»¤åˆ—åƒæ•¸

### è³‡æ–™ç›¸é—œ

```bash
--train_data dataset/train.txt        # è¨“ç·´è³‡æ–™åˆ—è¡¨
--val_data dataset/valid.txt          # é©—è­‰è³‡æ–™åˆ—è¡¨
--crop_length 256                     # è£å‰ªé•·åº¦ï¼ˆ128/256/512ï¼‰
--augment_factor 1                    # æ¯å€‹ MIDI ç”Ÿæˆå¹¾å€‹éš¨æ©Ÿè£å‰ª
--pitch_shift_min -3                  # éŸ³é«˜åç§»æœ€å°å€¼ï¼ˆåŠéŸ³ï¼‰
--pitch_shift_max 3                   # éŸ³é«˜åç§»æœ€å¤§å€¼ï¼ˆåŠéŸ³ï¼‰
```

### è¨“ç·´è¶…åƒæ•¸

```bash
--train_batch_size 8                  # è¨“ç·´ batch size
--val_batch_size 8                    # é©—è­‰ batch size
--max_steps 200000                    # æœ€å¤§è¨“ç·´æ­¥æ•¸
--lr 1e-4                             # å­¸ç¿’ç‡
--warmup_steps 2000                   # Warmup æ­¥æ•¸
--weight_decay 0.05                   # Weight decay
--grad_clip 3.0                       # Gradient clipping
--accumulate_grad_batches 1           # Gradient accumulation
```

### æ¨¡å‹é…ç½®

```bash
--generator_types "mar,mar,mar,mar"   # æ¯å±¤çš„ç”Ÿæˆå™¨é¡å‹ï¼ˆmar æˆ– arï¼‰
--scan_order "row_major"              # AR æƒæé †åºï¼ˆrow_major æˆ– column_majorï¼‰
--mask_ratio_loc 1.0                  # MAR mask ratio å¹³å‡å€¼
--mask_ratio_scale 0.5                # MAR mask ratio æ¨™æº–å·®
```

### ç¡¬é«”è¨­ç½®

```bash
--devices "0,1"                       # GPU ç´¢å¼•ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰
--num_workers 4                       # DataLoader workers
--precision "32"                      # è¨“ç·´ç²¾åº¦ï¼ˆ32/16/bf16ï¼‰
--grad_checkpoint                     # å•Ÿç”¨ gradient checkpointingï¼ˆçœè¨˜æ†¶é«”ï¼‰
```

### Logging å’Œ Checkpointing

```bash
--output_dir outputs/my_model         # è¼¸å‡ºç›®éŒ„
--log_every_n_steps 50                # Logging é »ç‡
--val_check_interval_steps 2000       # é©—è­‰é »ç‡
--checkpoint_every_n_steps 5000       # Checkpoint é »ç‡
--log_images_every_n_steps 5000       # ç”Ÿæˆæ¨£æœ¬é »ç‡
--save_top_k 3                        # ä¿ç•™æœ€å¥½çš„ k å€‹ checkpoints
```

## Generator é¡å‹é…ç½®

æ¯å€‹å±¤ç´šå¯ä»¥ç¨ç«‹é¸æ“‡ç”Ÿæˆå™¨é¡å‹ï¼š

### MAR (Masked Autoregressive)
- **å„ªé»**ï¼šä¸¦è¡Œç”Ÿæˆã€è¨“ç·´ç©©å®šã€å“è³ªé«˜
- **ç¼ºé»**ï¼šéœ€è¦å¤šæ¬¡è¿­ä»£
- **é©ç”¨**ï¼šå¤§éƒ¨åˆ†å ´æ™¯

### AR (Autoregressive)
- **å„ªé»**ï¼šåºåˆ—åŒ–ç”Ÿæˆã€ç´°ç¯€æ§åˆ¶å¥½
- **ç¼ºé»**ï¼šæ…¢ã€å®¹æ˜“ç´¯ç©éŒ¯èª¤
- **é©ç”¨**ï¼šéœ€è¦ç²¾ç¢ºæ§åˆ¶ç”Ÿæˆé †åºæ™‚

### å»ºè­°é…ç½®

```bash
# å…¨ MARï¼ˆæ¨è–¦ï¼‰
--generator_types "mar,mar,mar,mar"

# å…¨ AR
--generator_types "ar,ar,ar,ar"

# æ··åˆï¼ˆé«˜å±¤ MARï¼Œä½å±¤ ARï¼‰
--generator_types "mar,mar,ar,ar"
```

## Scan Orderï¼ˆåƒ… ARï¼‰

å°æ–¼ AR ç”Ÿæˆå™¨ï¼Œå¯ä»¥é¸æ“‡æƒæé †åºï¼š

### row_majorï¼ˆè¡Œå„ªå…ˆï¼‰
- æƒæé †åºï¼šå…ˆæƒæå®Œä¸€è¡Œï¼Œå†æ›ä¸‹ä¸€è¡Œ
- å°æ–¼ piano roll (128, W)ï¼šå…ˆæƒæå®Œæ‰€æœ‰æ™‚é–“æ­¥ï¼Œå†æ›éŸ³é«˜
- **é©åˆ**ï¼šæ—‹å¾‹ç·šã€å–®éŸ³åºåˆ—

### column_majorï¼ˆåˆ—å„ªå…ˆï¼‰
- æƒæé †åºï¼šå…ˆæƒæå®Œä¸€åˆ—ï¼Œå†æ›ä¸‹ä¸€åˆ—
- å°æ–¼ piano roll (128, W)ï¼šå…ˆæƒæå®Œæ‰€æœ‰éŸ³é«˜ï¼Œå†æ›æ™‚é–“æ­¥
- **é©åˆ**ï¼šå’Œå¼¦çµæ§‹ã€å‚ç›´å’Œè²

```bash
# å»ºè­°å˜—è©¦å…©ç¨®éƒ½è¨“ç·´æ¯”è¼ƒ
bash train_128x128.sh  # é è¨­ row_major
# ä¿®æ”¹è…³æœ¬ä¸­çš„ SCAN_ORDER="column_major" å†è¨“ç·´ä¸€æ¬¡æ¯”è¼ƒ
```

## è¨˜æ†¶é«”å„ªåŒ–

å¦‚æœé‡åˆ° OOM (Out of Memory)ï¼š

### 1. æ¸›å°‘ batch size
```bash
--train_batch_size 4  # æˆ–æ›´å°
```

### 2. å•Ÿç”¨ gradient checkpointing
```bash
--grad_checkpoint
```
æ³¨æ„ï¼šæœƒç¨å¾®é™ä½è¨“ç·´é€Ÿåº¦

### 3. ä½¿ç”¨æ··åˆç²¾åº¦
```bash
--precision "bf16"  # æˆ– "16"
```

### 4. æ¸›å°‘ DataLoader workers
```bash
--num_workers 2
```

### 5. ç¦ç”¨ in-memory cache
```bash
--no_cache_in_memory
```

## è¨“ç·´ç›£æ§

### TensorBoard

```bash
tensorboard --logdir outputs/my_model/logs
```

æŸ¥çœ‹ï¼š
- Loss curves
- Learning rate schedule
- Generated samples
- æ¯å±¤çš„çµ±è¨ˆè³‡è¨Š

### æª¢æŸ¥ Checkpoints

Checkpoints å„²å­˜åœ¨ï¼š
```
outputs/my_model/checkpoints/
â”œâ”€â”€ step_00005000-val_loss_0.0234.ckpt
â”œâ”€â”€ step_00010000-val_loss_0.0198.ckpt
â””â”€â”€ ...
```

## å¾ Checkpoint æ¢å¾©è¨“ç·´

å¦‚æœè¨“ç·´ä¸­æ–·ï¼Œå¯ä»¥å¾ checkpoint æ¢å¾©ï¼š

```bash
python main.py \
    --crop_length 256 \
    --train_batch_size 8 \
    --output_dir outputs/my_model \
    --resume_from_checkpoint outputs/my_model/checkpoints/latest.ckpt
```

## è¨“ç·´å¾Œæ¸¬è©¦

è¨“ç·´å®Œæˆå¾Œï¼Œä½¿ç”¨æ¨ç†è…³æœ¬æ¸¬è©¦ï¼š

```bash
# å°æ–¼ 128Ã—128 æ¨¡å‹
python inference.py \
    --checkpoint outputs/my_128x128_model/checkpoints/best.ckpt \
    --target_width 128 \
    --num_samples 10 \
    --output_dir outputs/test_generation

# å°æ–¼ 256Ã—256 æ¨¡å‹ï¼ˆ128Ã—512ï¼‰
python inference.py \
    --checkpoint outputs/my_256x256_model/checkpoints/best.ckpt \
    --target_width 512 \
    --num_samples 10 \
    --output_dir outputs/test_generation
```

## å¸¸è¦‹å•é¡Œ

### Q: æ‡‰è©²é¸æ“‡å“ªå€‹æ¨¡å‹å¤§å°ï¼Ÿ

**A:** 
- å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¨“ç·´ï¼šé¸ 128Ã—128ï¼Œè¨“ç·´å¿«ã€é™¤éŒ¯å®¹æ˜“
- å¦‚æœéœ€è¦é•·åºåˆ—ï¼šé¸ 256Ã—256ï¼ˆ512ï¼‰
- å¯ä»¥å…ˆè¨“ç·´ 128Ã—128ï¼Œå† fine-tune åˆ°æ›´å¤§å°ºå¯¸

### Q: è¨“ç·´éœ€è¦å¤šä¹…ï¼Ÿ

**A:**
- 128Ã—128ï¼š2-4 å¤©ï¼ˆé›™ GPUï¼Œ200k stepsï¼‰
- 256Ã—256ï¼š4-7 å¤©ï¼ˆé›™ GPUï¼Œ200k stepsï¼‰

### Q: å¦‚ä½•çŸ¥é“è¨“ç·´æ˜¯å¦æ”¶æ–‚ï¼Ÿ

**A:** è§€å¯Ÿï¼š
- Validation loss ç©©å®šä¸‹é™
- Generated samples å“è³ªé€æ¼¸æå‡
- å„å±¤çš„ loss contribution è¶¨æ–¼ç©©å®š

### Q: å¯ä»¥æ”¹è®Š crop_length å—ï¼Ÿ

**A:** å¯ä»¥ï¼æ”¯æ´ä»»ä½•æ˜¯ 4 çš„å€æ•¸çš„é•·åº¦ï¼š
```bash
--crop_length 64   # æœ€å°
--crop_length 128  # æ¨™æº–å°
--crop_length 256  # æ¨™æº–ä¸­
--crop_length 512  # æ¨™æº–å¤§
--crop_length 1024 # è¶…å¤§ï¼ˆéœ€è¦å¤§é‡è¨˜æ†¶é«”ï¼‰
```

### Q: MAR å’Œ AR å“ªå€‹å¥½ï¼Ÿ

**A:** 
- **MAR**ï¼šé€šå¸¸å“è³ªæ›´å¥½ã€è¨“ç·´æ›´ç©©å®šï¼ˆæ¨è–¦ï¼‰
- **AR**ï¼šé©åˆéœ€è¦ç²¾ç¢ºæ§åˆ¶ç”Ÿæˆé †åºçš„å ´æ™¯
- å»ºè­°å…ˆå…¨ç”¨ MARï¼Œæœ‰éœ€è¦å†å˜—è©¦æ··åˆ

## ç¯„ä¾‹å·¥ä½œæµç¨‹

### å®Œæ•´è¨“ç·´æµç¨‹

```bash
# 1. æ¸¬è©¦ç’°å¢ƒ
bash train_test.sh

# 2. è¨“ç·´ 128Ã—128 æ¨¡å‹ï¼ˆå¿«é€ŸåŸå‹ï¼‰
bash train_128x128.sh

# 3. æ¸¬è©¦ç”Ÿæˆ
python inference.py \
    --checkpoint outputs/fractalgen_128x128/checkpoints/step_00100000-val_loss_0.0123.ckpt \
    --target_width 128 \
    --num_samples 20

# 4. å¦‚æœæ•ˆæœå¥½ï¼Œè¨“ç·´æ›´å¤§æ¨¡å‹
bash train_256x256.sh

# 5. æœ€çµ‚æ¸¬è©¦
python inference.py \
    --checkpoint outputs/fractalgen_256x256/checkpoints/step_00150000-val_loss_0.0089.ckpt \
    --target_width 512 \
    --num_samples 50 \
    --temperature 0.9
```

## é€²éšæŠ€å·§

### 1. å…©éšæ®µè¨“ç·´

å…ˆè¨“ç·´å°æ¨¡å‹ï¼Œå† fine-tune åˆ°å¤§å°ºå¯¸ï¼š

```bash
# Stage 1: Train on 128Ã—128
python main.py --crop_length 128 --max_steps 100000 --output_dir outputs/stage1

# Stage 2: Fine-tune on 256Ã—256
python main.py --crop_length 256 --max_steps 50000 \
    --resume_from_checkpoint outputs/stage1/checkpoints/latest.ckpt \
    --output_dir outputs/stage2
```

### 2. å¯¦é©—ä¸åŒé…ç½®

```bash
# Experiment 1: All MAR
python main.py --crop_length 256 --generator_types "mar,mar,mar,mar" \
    --output_dir outputs/exp_mar

# Experiment 2: All AR with row_major
python main.py --crop_length 256 --generator_types "ar,ar,ar,ar" \
    --scan_order "row_major" --output_dir outputs/exp_ar_row

# Experiment 3: All AR with column_major
python main.py --crop_length 256 --generator_types "ar,ar,ar,ar" \
    --scan_order "column_major" --output_dir outputs/exp_ar_col
```

### 3. è³‡æ–™å¢å¼·èª¿æ•´

```bash
# Heavy augmentation
python main.py --crop_length 256 \
    --augment_factor 4 \
    --pitch_shift_min -6 \
    --pitch_shift_max 6

# Minimal augmentation
python main.py --crop_length 256 \
    --augment_factor 1 \
    --pitch_shift_min 0 \
    --pitch_shift_max 0
```

## æª”æ¡ˆçµæ§‹

è¨“ç·´å¾Œçš„è¼¸å‡ºçµæ§‹ï¼š

```
outputs/my_model/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ step_00005000-val_loss_0.0234.ckpt
â”‚   â”œâ”€â”€ step_00010000-val_loss_0.0198.ckpt
â”‚   â””â”€â”€ ...
â””â”€â”€ logs/
    â””â”€â”€ version_0/
        â”œâ”€â”€ events.out.tfevents...  # TensorBoard logs
        â””â”€â”€ hparams.yaml            # Hyperparameters
```

ç¥è¨“ç·´é †åˆ©ï¼ğŸµ

